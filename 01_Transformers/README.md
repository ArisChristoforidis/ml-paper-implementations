# Transformers

This implementation of transformers is based on the [Attention Is All You Need](https://arxiv.org/abs/1706.03762) paper.